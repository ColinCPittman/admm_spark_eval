services:
  spark-master:
    build:
      context: ./spark-2.4
      dockerfile: Dockerfile
    container_name: spark-master
    command: >
      /bin/bash -c "
      /opt/spark/sbin/start-master.sh &&
      tail -f /dev/null
      "
    ports:
      - "7077:7077"
      - "8080:8080"
    networks:
      - sparknet

  spark-worker:
    build:
      context: ./spark-2.4
      dockerfile: Dockerfile
    container_name: spark-worker
    command: >
      /bin/bash -c "
      /opt/spark/sbin/start-slave.sh spark://spark-master:7077 &&
      tail -f /dev/null
      "
    depends_on:
      - spark-master
    volumes:
      - ../data:/workspace/data
      - ../src:/workspace/src
      - ../notebooks:/workspace/notebooks
    environment:
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=12g
    networks:
      - sparknet
    deploy:
      resources:
        limits:
          memory: 16G
        reservations:
          memory: 8G

  spark24:
    build:
      context: ./spark-2.4
      dockerfile: Dockerfile
    container_name: spark-2.4-env
    depends_on:
      - spark-master
      - spark-worker
    volumes:
      - ../data:/workspace/data
      - ../src:/workspace/src
      - ../notebooks:/workspace/notebooks
      - ./conf/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    networks:
      - sparknet
    working_dir: /workspace
    tty: true
    stdin_open: true
    deploy:
      resources:
        limits:
          memory: 16G
        reservations:
          memory: 8G

  spark-master-40:
    build:
      context: ./spark-4.0
      dockerfile: Dockerfile
    container_name: spark-master-40
    command: >
      /bin/bash -c "
      /opt/spark/sbin/start-master.sh &&
      tail -f /dev/null
      "
    ports:
      - "7078:7077"
      - "8081:8080"
    networks:
      - sparknet
    deploy:
      resources:
        limits:
          memory: 16G
        reservations:
          memory: 8G

  spark-worker-40:
    build:
      context: ./spark-4.0
      dockerfile: Dockerfile
    container_name: spark-worker-40
    command: >
      /bin/bash -c "
      /opt/spark/sbin/start-worker.sh spark://spark-master-40:7077 &&
      tail -f /dev/null
      "
    depends_on:
      - spark-master-40
    volumes:
      - ../data:/workspace/data
      - ../src:/workspace/src
      - ../notebooks:/workspace/notebooks
    environment:
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=12g
    networks:
      - sparknet
    deploy:
      resources:
        limits:
          memory: 16G
        reservations:
          memory: 8G

  spark40:
    build:
      context: ./spark-4.0
      dockerfile: Dockerfile
    container_name: spark-4.0-env
    depends_on:
      - spark-master-40
      - spark-worker-40
    volumes:
      - ../data:/workspace/data
      - ../src:/workspace/src
      - ../notebooks:/workspace/notebooks
      - ./conf/spark-defaults-40.conf:/opt/spark/conf/spark-defaults.conf
    ports:
      - "4040:4040"
    networks:
      - sparknet
    working_dir: /workspace
    tty: true
    stdin_open: true
    deploy:
      resources:
        limits:
          memory: 16G
        reservations:
          memory: 8G   

networks:
  sparknet:
    driver: bridge